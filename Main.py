# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yYA987WhQ7pUD9PciyJ2M9BKcdGanMyF
"""

# To generate GIFs
!pip install imageio
!pip install git+https://github.com/tensorflow/docs

import tensorflow as tf
import glob
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
from tensorflow.keras import layers
import time
import cv2
from skimage.transform import resize
from IPython import display
import imageio

"""# **Import dataset as numpy array and resize images**"""

path = '/content/drive/MyDrive/ML dataset/CelebA dataset'
train_images = []
for i in os.listdir(path):
  train_images.append(resize(cv2.imread(path+'/'+i,0), (224, 224,1)))
  
train_images = np.array(train_images).astype('float32')
print(train_images.shape)

"""#**Create tensorflow batched dataset**"""

BATCH_SIZE = 8 
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)

"""# **Generator model**"""

def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(56*56*256, use_bias=False, input_shape=(224,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((56, 56, 256)))
    assert model.output_shape == (None, 56, 56, 256)  # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 56, 56, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 112, 112, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 224, 224, 1)

    return model

"""# **Discriminator model**"""

def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                            input_shape=[224, 224, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

"""# **Create loss functin and optimizer**"""

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

"""# **Function to calculate discriminator loss**"""

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss, real_loss, fake_loss

"""# **Function to calculate generator loss**"""

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

"""# **Determine epochs , noise dim and number of examples.**
# **Create seed to be used in testing the generator**
"""

EPOCHS = 20
noise_dim = 224
num_examples_to_generate = 16

seed = tf.random.normal([num_examples_to_generate, noise_dim])

"""# **Function to update weights after each training step**"""

@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss, real_loss, fake_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
    return gen_loss, disc_loss, real_loss, fake_loss

"""# **Function to train the model on batches and generate loss histograms**"""

def train(dataset, epochs):
  gen_hist = []
  disc_hist = []
  disc_real_hist = []
  disc_fake_hist = []
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      g_loss, d_loss, d_real_loss, d_fake_loss = train_step(image_batch)
      g_loss = g_loss.numpy()
      d_loss = d_loss.numpy()
      d_real_loss = d_real_loss.numpy()
      d_fake_loss = d_fake_loss.numpy()
      gen_hist.append(g_loss)
      disc_hist.append(d_loss)
      disc_real_hist.append(d_real_loss)
      disc_fake_hist.append(d_fake_loss)
    print("G_loss:", g_loss, "D_loss:", d_real_loss, d_fake_loss, d_loss)

 
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    if (epoch + 1) % epochs == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  generate_and_save_images(generator,
                           epochs,
                           seed)
  plot_history(disc_real_hist, disc_fake_hist, disc_hist, gen_hist)

"""# **Function to generate an image and save it in the directory**"""

def generate_and_save_images(model, epoch, test_input):

  predictions = model(test_input, training=False)

  fig = plt.figure(figsize=(4, 4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(predictions[i, :, :, 0] , cmap='gray')
      plt.axis('off')

  plt.savefig('/content/drive/MyDrive/Deeplearning/dcgan/Generated images/image_at_epoch_{:04d}.png'.format(epoch))
  plt.show()

"""# **Function to plot loss histogram**"""

def plot_history(d1_hist, d2_hist, d_hist, g_hist):
  # plot loss
  plt.plot(d1_hist, label='d-real')
  plt.plot(d2_hist, label='d-fake')
  plt.plot(d_hist, label='d-total')
  plt.plot(g_hist, label='gen')
  plt.legend()
  # save plot to file
  plt.savefig('/content/drive/MyDrive/Deeplearning/dcgan/plot_loss.png')
  plt.show()
  plt.close()

"""# **Create models and print summaries**"""

generator = make_generator_model()
print("Generator model") 
print(generator.summary())
print("\nDiscriminator model")
discriminator = make_discriminator_model()
print(discriminator.summary())

"""# **Create checkpoints by saving model weights**"""

checkpoint_dir = '/content/drive/MyDrive/Deeplearning/dcgan/Checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                  generator=generator,
                                 discriminator=discriminator)

"""# **Train the models**"""

train(train_dataset, EPOCHS)

"""# **Restore last checkpoint**"""

checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

"""# **Create gif image for the saved image after each epoch**"""

anim_file = 'dcgan.gif'
os.chdir('/content/drive/MyDrive/Deeplearning/dcgan/Generated images')
with imageio.get_writer(anim_file, mode='I') as writer:
  filenames = glob.glob('image*.png')
  filenames = sorted(filenames)
  for filename in filenames:
    image = imageio.imread(filename)
    writer.append_data(image)
  image = imageio.imread(filename)
  writer.append_data(image)

import tensorflow_docs.vis.embed as embed
embed.embed_file(anim_file)

"""# **Generate 10 random samples**"""

for i in range(10):
  noise = tf.random.normal([1, 224])
  generated_image = generator(noise, training=False)
  plt.imshow(generated_image[0, :, :, 0], cmap='gray')
  plt.savefig('/content/drive/MyDrive/Deeplearning/dcgan/Examples/{:04d}.jpg'.format(i))
  plt.show()